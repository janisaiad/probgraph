%% SIGGRAPH / ACM Conference Two-Column Template
%% Compile with: pdflatex, xelatex, or lualatex

\documentclass[sigconf,nonacm]{acmart}


\title{Project Report - Denoising Score Matching}
\subtitle{Probabilistic Graphical Models - MVA 2025-2026}



\author{Félix Rosseeuw}
\affiliation{
  \institution{}
  \city{}
  \country{}
}
\email{felix.rosseeuw@polytechnique.edu}

\author{Janis Aiad}
\affiliation{
  \institution{}
  \city{}
  \country{}
}
\email{janisaiad.ja@gmail.com}

\author{Guillaume Bernard}
\affiliation{
  \institution{}
  \city{}
  \country{}
}
\email{2000guiber@gmail.com}

% Remove ACM reference information for non-submissions
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\usepackage{graphicx}
\usepackage{amsmath, amsfonts}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{microtype}



\begin{document}


\maketitle


\section{Introduction}

\section{A Connection between Score Matching and Denoising Autoencoders}

\subsection{Contexte - Les autoencodeurs de débruitage}

Un \textit{autoencodeur} est un réseau de neurones qui apprend à reconstruire un échantillon d'entrée après l'avoir encodé en une représentation de dimension réduite appelée \textit{latente}. 

En limitant la dimension de l'espace contenant ces représentations, on contraint l'autoencodeur à y encoder des informations pertinentes pour la caractérisation des données. En revanche, si l’espace \textit{latent} est d'une dimension trop élevée, l’autoencodeur risque d'apprendre une fonction triviale comme l’identité sans capturer la structure statistique des données.

Pour remédier à ce type de problèmes, Vincent et al. ont introduit en 2008 les autoencodeurs \textit{de débruitage} \cite{vincent2008denoising}. Le principe de ces réseaux consiste en l'ajout de bruit gaussien aux échantillons afin d'en obtenir des versions corrompues. En d'autres termes, pour $x$ dans l'ensemble d'entraînement, on génère
$$\tilde{x}=x+\varepsilon \mathrm{\ avec\ } \varepsilon\sim \mathcal{N}(0,\sigma^2)$$
Ensuite, à l'instar du fonctionnement d'un autoencodeur habituel, cet échantillon corrompu $\tilde{x}$ est encodé en une représentation latente, puis cette représentation est décodée en une reconstruction $x^r=\mathrm{decode}(\mathrm{encode}(\tilde{x}))$.

Dans ce cadre, l'\textit{entraînement} un autoencodeur de débruitage correspond à l'optimisation de ses paramètres $\theta$ afin qu'ils minimisent l'erreur quadratique moyenne entre un échantillon $x$ et sa reconstruction $x^r$. En d'autres termes, il s'agit de minimiser la fonction $$J_{DAE_{\sigma}}(\theta)=\mathbb{E}_{q_{\sigma}(\tilde{x},x)}[||x^r-x||^2]$$
où $q_{\sigma}(\tilde{x},x)=q_{\sigma}(\tilde{x}|x)q_0(x)$ désigne la distribution jointe définie par la loi empirique des données d'entraînement $q_0(x)$ et le processus de corruption gaussien $q_{\sigma}(\tilde{x}|x)$.

En pratique, les autoencodeurs de débruitage se sont révélés particulièrement efficaces pour capturer la structure des données. Ils évitaient effectivement l’apprentissage de solutions triviales et produisaient des représentations plus robustes que les autoencodeurs classiques, mais malgré ce succès empirique, le mécanisme qu’ils apprenaient en reconstruisant les exemples corrompus restait mal compris.

C’est précisément à cette mauvaise compréhension que l’article de Pascal Vincent paru en 2011 \cite{vincent2011connection} vient apporter une réponse. Il met en lumière un lien théorique entre la reconstruction qu'effectue les autoencodeurs de débruitage et l’estimation du score de la distribution des données.

\subsection{Résultat principal}

Le \textit{score matching} est une technique introduite par Hyvärinen en 2005 \cite{hyvarinen2005score} qui sert à apprendre les paramètres d'un modèle de densité de probabilité $p(x;\theta)$ pour lequel la fonction de partition est intractable, c’est-à-dire impossible à calculer de manière exacte ou efficace en pratique. 

Le score matching contourne ce problème en utilisant uniquement le \textit{score} $\nabla_x \log p(x;\theta)$, le gradient de la densité logarithmique par rapport au vecteur des données, qui ne dépend pas de cette fonction de partition.

Le score matching consiste en l'apprentissage des paramètres $\theta$ afin que le score $\nabla_x \log p(x;\theta)$ corresponde le plus possible au score de la distribution $q(x)$ qui régit les données. En d'autres termes, cela consiste en la minimisation de la fonction $$J_{ESM_q}(\theta)=\mathbb{E}_{q(x)}[\frac{1}{2}||\nabla_x \log p(x;\theta)-\nabla_x \log q(x)||^2]$$
Cette version du score matching dite \textit{explicite} pose toutefois un problème pratique. Le fait que la distribution $q(x)$ soit inconnue empêche d'obtenir des valeurs cibles de $\nabla_x \log q(x)$ nécessaires à cette minimisation. 

Pour pallier à cette limitation, plusieurs variantes dites \textit{implicites} du score matching ont été développées. Ces approches remplacent l’objectif explicite ci-dessus par des critères mathématiquement équivalents mais qui ne nécessitent pas l’accès au score de la distribution cible.

Dans son article de 2011, Vincent propose de modifier l'objectif de score matching explicite en appariant le score $\nabla_x \log p(x;\theta)$ avec celui d'un estimateur de densité de Parzen $q_{\sigma}(\tilde{x})$, une méthode qui sert à approximer la densité de probabilité d’un ensemble de données.

Ce nouvel objectif de score score matching explicite s'exprime comme la minimisation de la fonction $$J_{ESM_{q_{\sigma}}}(\theta)=\mathbb{E}_{q_{\sigma}(\tilde{x})}[\frac{1}{2}||\nabla_{\tilde{x}} \log p(\tilde{x};\theta)-\nabla\tilde{x} \log q_{\sigma}(\tilde{x})||^2]$$

Afin de démontrer son résultat, Vincent introduit ensuite un nouvel objectif de score matching dit \textit{score matching de débruitage} qui consiste en la minimisation de la fonction
$$J_{DSM_{q_{\sigma}}}(x,\theta)=\mathbb{E}_{q_{\sigma}(\tilde{x})}[\frac{1}{2}||\nabla_{\tilde{x}} \log p(\tilde{x};\theta)-\nabla\tilde{x} \log q_{\sigma}(\tilde{x}|x)||^2]$$

Afin de se représenter intuitivement ce que représente cet objectif, il est utile de remarquer que $\nabla\tilde{x} \log q_{\sigma}(\tilde{x}|x)=\frac{1}{\sigma^2}(x-\tilde{x})$, qui est un mouvement allant de $\tilde{x}$ dans la direction de $x$. Ainsi, le score matching de débruitage contraint le score à ressembler le plus possible à cette direction, et ainsi à se diriger le plus possible vers l'échantillon véritable $x$.

Ce que montre ensuite Vincent, c'est l'équivalence entre les trois problèmes $$J_{ESM_{q_{\sigma}}}\smile J_{DSM_{q_{\sigma}}}\smile J_{DAE_{\sigma}}$$.

En d'autres termes, entraîner un autoencodeur de débruitage équivaut à faire du score matching avec un estimateur de densité de Parzen $q_{\sigma}$.


\subsection{Conséquences}

Ce que cette découverte signifie, et surtout pour l'article suivant.

notamment dans la modélisation générative, ce qui est montré dans l'article présenté dans la section suivante.

\section{Generative Modeling by Estimating Gradients of the
Data Distribution}

\subsection{Contexte}

La \textit{modélisation générative} consiste en l'apprentissage d'un modèle capable de générer, à partir d'un ensemble d'exemples tirés d'une distribution $q$, de nouveaux échantillons cohérents avec cette distribution.

Avant l'introduction de la modélisation générative basée sur le score par Song et Ermon \cite{song2019score}, cette tâche était effectuée par des GANs et des méthodes basées sur la vraisemblance. Ces méthodes avaient leur limitations intrinsèques, et l'introduction de Song et Ermon permettent de coutourner tout ça.

Comme vu dans la section précédente, le score matching de débruitage induit un déplacement local des échantillons corrompus vers les données. Song et Ermon exploitent cette propriété en apprenant ce déplacement au moyen d'un \textit{réseau de score}.

Concrètement, leur méthode consiste à apprendre un \textit{réseau de score} $s_{\theta}:\mathbb{R}^D\rightarrow\mathbb{R}^D$ qui approxime le score de la distribution des données $\nabla_x q(x;\theta)$ pour tout $x$ dans l'espace ambiant. 

Comme vu dans la section précédente, le score pointe vers les régions de forte densité, c'est d'apprendre un champ de vecteurs qui pointent vers les régions de forte densité, ramener les échantillons samplés vers la vraie distribution des données.\\
\\

Plusieurs obstacles empêchaient en effet de mettre en place une application naïve de cette idée.

L'\textit{hypothèse de la variété} stipule que les données se situent sur une variété de faible dimension contenue dans l'espace ambiant de haute dimensionsous-dimensionnée dans un espace à plus grande dimension. 

Si cette hypothèse s'avère vraie, alors leur support a une mesure de Lebesgue nulle et n'admettent pas de densité par rapport à cette mesure. Par conséquent, non seulement le score est indéfini, ...

mais le score matching est impossible.

Deux autres problèmes liés aux régions de faible densité de données : Ensuite, en supposant que le premier problème soit résolu et que le score soit définissable sur l'espace ambiant, les régions à faible densité de données représentent un problème à la fois pour le calcul du score et pour le sampling avec la dynamique de Langevin.

De plus, si deux modes d'une distribution sont séparées par une région de densité faible, alors le score va mal rendre compte du poids des modes.

Les différentes solutions que proposent Song et Ermon se base sur l'ajout de bruit.

\subsection{Résultat principal}

Pour le premier problème, on bruite les données pour que leur support ne soit plus limité à une variété, et que le score soit défini sur tout l'espace ambiant.

TOUT EXPLIQUER AVEC LE DSM ET TOUT
 


\subsection{Conséquences}
Avant les travaux de Song et Ermon, cette tâche était principalement effectuée par des GANs et des méthodes basées sur la vraisemblance, mais ils ont proposé quelque chose de nouveau.





\section{Pourquoi ajouter de la stochasticité ?}

\section{Le score matching a bien fait de l'ajouter car biais inductif + naturel}

Passer de flow matching à diffusion models n'est pas juste une généralisation hasardueuse, mapper une distribution vers une autre sans aspect probabiliste c'est du flow matching, le calcul stochastique nous dit que le flow matching est inclut dans toute une classe de variation probabiliste, qui transforme le probleme de sampling ODE déterministe vers un problème de MCMC langevin.

L'ajout de cette stochasticité rend la transformation image - gaussienne beaucoup plus naturelle (en fait c'est la bonne généralisation d'ajouter du bruit gaussien d'un point de vue transport optimal) 

Il se trouve qu'en écrivant l'équation backward on peut estimer le transport gaussienne - image SANS avoir accès à toutes les distributions p_theta, c'est le début de l'estimation du score direct sans passer par le gradient de la distribution. 

L'usage du score au lieu de la parametrisation directe de la distribution (example une mixture de gaussienne) n'est pas qu'un artefact d'analyse numérique qui permet de mapper les queues de distributions en 0 vers -inf, c'est le score qui est l'unique valeur necessaire pour sampler une image.


Apporter de la stochasticité a aussi un autre effet désirable, celui de régularisation de la qualité des images.
Un flow matching mal appris va transformer une image vers une version ou les details peuvent etre mal appris.

Le debruitage successif etant le biais inductif du modele (c'est à dire ce que le modèle fait de mieux en terme conceptuel), notre image finale a tout simplement moins de bruit, parce que l'on débruite.

Ceci s'explique très bien lorsque l'on écrit les équations de transport

d'un cote on a l'equation de la chaleur et de l'autre une equation de transport classique ; puisque l'equation de la chaleur forward rend les distributions + smooth, en inversant la fleche du temps, l'equation de la chaleur backward a naturellement une tendance à créer des pics dans la distribution,x



Ceci était le chemin conceptuel qui a leadé de 2015 à  2022,

Cependant, la plupart des taches d'IA n'étant pas seulement celle d'IA generative, certains problemes classiques en computational sciences ont commencé à etre ré-interprété comme des sous instances de problemes de transport (exemple du color impainting, changement de colorimétrie) ou changement de genre et de style sur des images , Ces problemes etaient auparavants traités sous l'angle du transport optimal qui donnait un cadre mathématique précis.
Ce cadre n'est pas unique, il est possible de passer d'une distribution à une autre avec autre chose qu'un plan de transport complexe a calculer, et c'est l'enjeu de la généralisation vers les stochastic interpolants


"emma 21 shows that it is insufficient in general to match ˆ b with b to obtain control on
the KL divergence. The essence of the problem is that a small error in ˆ b− b does not ensure
18
Stochastic Interpolants
control on the Fisher divergence FI(ρ(t) ∥ ˆρ(t)) = Rd 
|∇logρ(t,x) − ∇log ˆρ(t,x)|2 ρ(t,x)dx,
which is necessary due to the presence of (∇log ˆρ− ∇logρ) in""" ceci explique pourquoi il faut faire + que du flow matching, on ne controle pas ce qui se passe quand on prend juste b en flow matching


\subsection{ce qu'apporte les stochastic interpolants}

Passer d'une distribution gaussienne à image n'est pas souhaitable dans ces cas là, on veut passer d'une image de singe bleu à une image de singe vert. On peut faire un transport optimal dans l'espace colorimétrique.

cependant le cout computationnel sur de grandes images est rhédibitoire, le plan de transport atteignant 10**12 valeurs pour une image 1024*1024


c'est ce que stochatisc interpolants tente de résoudre en Apprenant à faire du transport de distribution de manière générale. Il ne s'agit pas forcément de passer par un 

La encore le flow matching répond à cette question de manière naturelle, mais pour de la colorimétrie la structure de l'image DOIT etre respectée (pétale, fleur, pistil dans le papier);

ce sont les détails qui comptent, et le flow matching n'excelle pas dans les détails. En revanche le biais inductif d'une équation de transport n'est intéressant que dans un sens, et pour du color impainting on a besoin des 2 côtés d'avoir ce biais inductif, ce qui est un peu complexe avec une equation de la chaleur qui n'a qu'un sens

remark 20 : This
is all that matters when applying these processes as generative models. However, the fact that
these processes are different has implications for the accuracy of the numerical integration
used to sample from them at any t as well as for the propagation of statistical errors (see
also the next remark)



Le genie des stochastic interpolants vient dans l'interpretation que l'equation de la chaleur provient de la SDE, mais cette SDE en l'intégrant nous donne un barycentre exponentiel entre image initiale et gaussienne z = somme (zi)/n (somme de gaussienne = gaussienene), mais écrire ça revient à se replacer dans le flow matching


Remark 11 If we set γ(t) = 0 in xt (i.e, if we remove the latent variable), the stochastic
interpolant (2.1) reduces to the one originally considered in Albergo and Vanden-Eijnden
(2023). In this setup, the results above formally stand except that we cannot guarantee the
spatial regularity of b(t,x) and s(t,x), since it relies on the presence of the latent variable (as
shown in the proof of Theorem 6). Hence, we expect the introduction of the latent variable
γ(t)z to help for generative modeling, where the solution to the corresponding ODEs/SDEs
will be better behaved, and for statistical approximation, since the targets b and s will be
more regular. We will see in Section 6 that it also gives us much greater flexibility in the
way we can bridge ρ0 and ρ1, which will enable us to design generative models with appealing
properties


conclusion il y a un compromis entre l'écriture compressée du flow matching qui est moins précise apres discretization (puisque l'on discretise rien en fait on apprend x1-x0) sur les détails et l'écriture super précise du diffusion model mais qui n'est valable que pour gaussienne into image

conclusion et si on faisait image into un peu gaussienne into image2 ! c'est de là que vient les stochastic interpolants, on essaye de récuperer ce qui fonctionne dans les 2 parties : une ecriture compressée qui necessite la connaisasnce d'une seule distirbution en plus (gaussienne) et le sampling sur les détails hyper précis d'un diffusion model


Remark 12 We will see in Section 2.4 that the forward and backward FPE in (2.20) and
(2.22) are more robust than the TE in (2.9) against approximation errors in the velocity
b and the score s, which has practical implications for generative models based on these
equations



en introduisant cette 3eme distribution au milieu, on se place dans le cadre du stochastic interpolants


il se trouve, et c'est une magie , si l'on écrit un ansatz de superposition brownian bridge + transport (xd
t=I(t,x0,x1)+Nt (2.6)
whereN: [0,1]→Rd isazero-meanGaussianstochasticprocessconstrainedtosatisfy
Nt=0=Nt=1=0.) 

alors on peut apprendre I via le vecteur vitesse de la neural ODE b et une stochasticité arbitraire modélisée par eps, on peut se permettre de choisir une stochasticité optimale ! c'est là l'utilité des stochastic interpolants !



il faut bien comprendre que l'on apprend b et s, mais qu'on fait l'inference à epsilon quelconque


Attention le choix de epsilon optimal n'est pas trivial, on a une upper bound qui nous sert si on la mimimize qui donne l'quation 2.49 mais en génral on ne sait pas, il faut faire du trial and error ou le porter en connaissance fondaamentale

conclusion : on va faire des experiences sur cet epsilon optimal 







\section{experiences}




j'ai eu boffi en seminaire qui m'a dit que choisir le epsilon optimal est important selon les classes de problemes (il m'avait parlé d'une startup qui utilise ça avec des protéines), on peut se permettre de diminuer grandement le nombre de pas et améliorer l'efficacité at the edge of the stabiility ! 














(on va faire des experiences sur cet epsilon optimal pour montrer direct combien de sous ça fait gagner)


\bibliographystyle{ACM-Reference-Format}
\bibliography{references}


\end{document}
