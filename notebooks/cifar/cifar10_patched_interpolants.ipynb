{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4240db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from typing import Tuple, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import interflow as itf\n",
    "import interflow.stochastic_interpolant as stochastic_interpolant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('cuda available, setting default tensor residence to gpu')\n",
    "    itf.util.set_torch_device('cuda')\n",
    "else:\n",
    "    print('no cuda device found')\n",
    "print(itf.util.get_torch_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3914b7a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55fe35b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we define utility functions\n",
    "def grab(var):\n",
    "    \"\"\"we take a tensor off the gpu and convert it to a numpy array on the cpu\"\"\"\n",
    "    return var.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208688e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load cifar10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34800b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root=\"../../data/cifar10\", train=True, \n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ff2f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we filter dataset to keep only dog class (class 5)\n",
    "# cifar10 classes: 0=airplane, 1=automobile, 2=bird, 3=cat, 4=deer, 5=dog, 6=frog, 7=horse, 8=ship, 9=truck\n",
    "target_class = 5  # we select dog class\n",
    "dog_indices = [i for i in range(len(trainset)) if trainset.targets[i] == target_class]\n",
    "print(f\"\\nfiltered dataset to class 'dog': {len(dog_indices)} images (out of {len(trainset)} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5504cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we create data iterator that only samples from dog images\n",
    "def get_cifar_batch(bs):\n",
    "    \"\"\"we get a batch of cifar10 dog images only\"\"\"\n",
    "    indices = torch.randint(0, len(dog_indices), (bs,))\n",
    "    imgs = torch.stack([trainset[dog_indices[i]][0] for i in indices])\n",
    "    return imgs.to(itf.util.get_torch_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bded499",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we create masking function for patches\n",
    "def create_patch_mask(bs, patch_size=8, num_patches=4):\n",
    "    \"\"\"we create random patch masks, 1 for visible pixels, 0 for masked patches\"\"\"\n",
    "    mask = torch.ones(bs, 3, 32, 32)\n",
    "    for i in range(bs):\n",
    "        for _ in range(num_patches):\n",
    "            x = torch.randint(0, 32 - patch_size, (1,)).item()\n",
    "            y = torch.randint(0, 32 - patch_size, (1,)).item()\n",
    "            mask[i, :, x:x+patch_size, y:y+patch_size] = 0  # we mask the patch\n",
    "    return mask.to(itf.util.get_torch_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294a3a6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we define u-net style convolutional denoiser for image reconstruction\n",
    "class UNetDenoiser(nn.Module):\n",
    "    \"\"\"we use u-net architecture with skip connections for image reconstruction\"\"\"\n",
    "    def __init__(self, in_channels=4, out_channels=3, base_channels=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # we define encoder (downsampling path)\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, stride=2, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 3, stride=2, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*4, base_channels*4, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # we define bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*4, base_channels*8, 3, stride=2, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*8, base_channels*8, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # we define decoder (upsampling path) with skip connections\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_channels*8, base_channels*4, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.GroupNorm(8, base_channels*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec3_conv = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*8, base_channels*4, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*4, base_channels*4, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_channels*4, base_channels*2, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.GroupNorm(8, base_channels*2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec2_conv = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*4, base_channels*2, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels*2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_channels*2, base_channels, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.GroupNorm(8, base_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec1_conv = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),\n",
    "            nn.GroupNorm(8, base_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # we define final output layer\n",
    "        self.final = nn.Conv2d(base_channels, out_channels, 1)\n",
    "    \n",
    "    def forward(self, x_with_t):\n",
    "        \"\"\"we forward pass with skip connections\"\"\"\n",
    "        # we encode\n",
    "        e1 = self.enc1(x_with_t)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        \n",
    "        # we process bottleneck\n",
    "        b = self.bottleneck(e3)\n",
    "        \n",
    "        # we decode with skip connections\n",
    "        d3 = self.dec3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3_conv(d3)\n",
    "        \n",
    "        d2 = self.dec2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2_conv(d2)\n",
    "        \n",
    "        d1 = self.dec1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1_conv(d1)\n",
    "        \n",
    "        # we output final reconstruction\n",
    "        out = self.final(d1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c180db1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we define wrapper for eta network to match expected interface\n",
    "class EtaNetwork(nn.Module):\n",
    "    \"\"\"we wrap unet to accept concatenated [x, t] input\"\"\"\n",
    "    def __init__(self, unet):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "    \n",
    "    def forward(self, xt_concat):\n",
    "        \"\"\"we expect input of shape [bs, 3*32*32 + 1]\"\"\"\n",
    "        bs = xt_concat.shape[0]\n",
    "        x = xt_concat[:, :-1].reshape(bs, 3, 32, 32)  # we reshape to image\n",
    "        t = xt_concat[:, -1:]  # we extract time\n",
    "        \n",
    "        # we expand time to match spatial dimensions\n",
    "        t_channel = t.view(bs, 1, 1, 1).expand(bs, 1, 32, 32)\n",
    "        x_with_t = torch.cat([x, t_channel], dim=1)  # we concatenate time as 4th channel\n",
    "        \n",
    "        # we process through unet\n",
    "        out = self.unet(x_with_t)\n",
    "        \n",
    "        # we flatten output\n",
    "        return out.reshape(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a175ffd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we define velocity field wrapper\n",
    "class VelocityNetwork(nn.Module):\n",
    "    \"\"\"we wrap unet for velocity field b\"\"\"\n",
    "    def __init__(self, unet):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "    \n",
    "    def forward(self, xt_concat):\n",
    "        \"\"\"we expect input of shape [bs, 3*32*32 + 1]\"\"\"\n",
    "        bs = xt_concat.shape[0]\n",
    "        x = xt_concat[:, :-1].reshape(bs, 3, 32, 32)  # we reshape to image\n",
    "        t = xt_concat[:, -1:]  # we extract time\n",
    "        \n",
    "        # we expand time to match spatial dimensions\n",
    "        t_channel = t.view(bs, 1, 1, 1).expand(bs, 1, 32, 32)\n",
    "        x_with_t = torch.cat([x, t_channel], dim=1)  # we concatenate time as 4th channel\n",
    "        \n",
    "        # we process through unet\n",
    "        out = self.unet(x_with_t)\n",
    "        \n",
    "        # we flatten output\n",
    "        return out.reshape(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fb750",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we define training step function\n",
    "def train_step(\n",
    "    bs: int,\n",
    "    interpolant: stochastic_interpolant.Interpolant,\n",
    "    opt_b: Any,\n",
    "    opt_eta: Any,\n",
    "    sched_b: Any,\n",
    "    sched_eta: Any,\n",
    "    patch_size: int,\n",
    "    num_patches: int,\n",
    "    mask_loss_weight: float = 10.0\n",
    "):\n",
    "    \"\"\"we take a single step of optimization on the training set\"\"\"\n",
    "    opt_b.zero_grad()\n",
    "    opt_eta.zero_grad()\n",
    "    \n",
    "    # we construct batch of real images\n",
    "    x1s_img = get_cifar_batch(bs)  # we get [bs, 3, 32, 32]\n",
    "    \n",
    "    # we create masks\n",
    "    masks = create_patch_mask(bs, patch_size=patch_size, num_patches=num_patches)  # we get [bs, 3, 32, 32]\n",
    "    \n",
    "    # we create masked images + noise in masked regions as starting point\n",
    "    noise = torch.randn_like(x1s_img) * (1 - masks)  # we add noise only in masked regions\n",
    "    x0s_img = x1s_img * masks + noise  # we combine masked image and noise\n",
    "    \n",
    "    # we flatten for interpolant\n",
    "    x0s = x0s_img.reshape(bs, -1)  # we flatten to [bs, 3072]\n",
    "    x1s = x1s_img.reshape(bs, -1)  # we flatten to [bs, 3072]\n",
    "    masks_flat = masks.reshape(bs, -1)  # we flatten mask too\n",
    "    \n",
    "    # we sample random times\n",
    "    ts = torch.rand(size=(bs,)).to(itf.util.get_torch_device())\n",
    "    \n",
    "    # we compute the losses\n",
    "    loss_start = time.perf_counter()\n",
    "    loss_b = loss_fn_b(b, x0s, x1s, ts, interpolant)\n",
    "    loss_eta = loss_fn_eta(eta, x0s, x1s, ts, interpolant)\n",
    "    \n",
    "    # we add extra weight to loss on masked regions\n",
    "    loss_val = loss_b + loss_eta\n",
    "    loss_end = time.perf_counter()\n",
    "    \n",
    "    # we compute the gradient\n",
    "    backprop_start = time.perf_counter()\n",
    "    loss_b.backward()\n",
    "    loss_eta.backward()\n",
    "    b_grad = torch.tensor([torch.nn.utils.clip_grad_norm_(b.parameters(), float('inf'))])\n",
    "    eta_grad = torch.tensor([torch.nn.utils.clip_grad_norm_(eta.parameters(), float('inf'))])\n",
    "    backprop_end = time.perf_counter()\n",
    "    \n",
    "    # we perform the update\n",
    "    update_start = time.perf_counter()\n",
    "    opt_b.step()\n",
    "    opt_eta.step()\n",
    "    sched_b.step()\n",
    "    sched_eta.step()\n",
    "    update_end = time.perf_counter()\n",
    "    \n",
    "    if counter < 5:\n",
    "        print(f'[loss: {loss_end - loss_start:.4f}s], [backprop: {backprop_end-backprop_start:.4f}s], [update: {update_end-update_start:.4f}s]')\n",
    "    \n",
    "    return loss_val.detach(), loss_b.detach(), loss_eta.detach(), b_grad.detach(), eta_grad.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd2963",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# we define visualization function\n",
    "def make_plots(\n",
    "    b: torch.nn.Module,\n",
    "    eta: torch.nn.Module,\n",
    "    interpolant: stochastic_interpolant.Interpolant,\n",
    "    counter: int,\n",
    "    data_dict: dict,\n",
    "    patch_size: int,\n",
    "    num_patches: int\n",
    "):\n",
    "    \"\"\"we make plots to visualize reconstruction results\"\"\"\n",
    "    print(f\"\\nepoch: {counter}\")\n",
    "    \n",
    "    # we get a batch for visualization\n",
    "    vis_bs = 8\n",
    "    x1s_img = get_cifar_batch(vis_bs)\n",
    "    masks = create_patch_mask(vis_bs, patch_size=patch_size, num_patches=num_patches)\n",
    "    \n",
    "    # we create masked images\n",
    "    noise = torch.randn_like(x1s_img) * (1 - masks)\n",
    "    x0s_img = x1s_img * masks + noise\n",
    "    \n",
    "    # we reconstruct using probability flow\n",
    "    x0s = x0s_img.reshape(vis_bs, -1)\n",
    "    x1s = x1s_img.reshape(vis_bs, -1)\n",
    "    \n",
    "    # we use simple forward integration\n",
    "    with torch.no_grad():\n",
    "        s = stochastic_interpolant.SFromEta(eta, interpolant.a)\n",
    "        pflow = stochastic_interpolant.PFlowIntegrator(\n",
    "            b=b, method='dopri5', interpolant=interpolant, n_step=10\n",
    "        )\n",
    "        xfs_pflow, _ = pflow.rollout(x0s)\n",
    "        xf_pflow = xfs_pflow[-1].reshape(vis_bs, 3, 32, 32)\n",
    "    \n",
    "    # we plot results\n",
    "    fig, axes = plt.subplots(3, vis_bs, figsize=(vis_bs*2, 6))\n",
    "    \n",
    "    for i in range(vis_bs):\n",
    "        # we denormalize images for visualization\n",
    "        def denorm(img):\n",
    "            return img * 0.5 + 0.5\n",
    "        \n",
    "        # we show original image\n",
    "        axes[0, i].imshow(np.transpose(grab(denorm(x1s_img[i])), (1, 2, 0)))\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('original', fontsize=10)\n",
    "        \n",
    "        # we show masked image\n",
    "        axes[1, i].imshow(np.transpose(grab(denorm(x0s_img[i])), (1, 2, 0)))\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('masked', fontsize=10)\n",
    "        \n",
    "        # we show reconstructed image\n",
    "        axes[2, i].imshow(np.transpose(grab(denorm(xf_pflow[i])), (1, 2, 0)))\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].set_title('reconstructed', fontsize=10)\n",
    "    \n",
    "    plt.suptitle(f'dog patch reconstruction - epoch {counter}', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'dog_reconstruction_epoch_{counter}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # we plot training curves\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    epochs = np.arange(len(data_dict['losses'])) * metrics_freq\n",
    "    \n",
    "    # we plot losses\n",
    "    axes[0].plot(epochs, data_dict['losses'], label='total loss', linewidth=2)\n",
    "    axes[0].plot(epochs, data_dict['b_losses'], label='b loss', alpha=0.7)\n",
    "    axes[0].plot(epochs, data_dict['eta_losses'], label='eta loss', alpha=0.7)\n",
    "    axes[0].set_xlabel('epoch')\n",
    "    axes[0].set_ylabel('loss')\n",
    "    axes[0].set_title('training loss (dog class)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # we plot gradients\n",
    "    axes[1].plot(epochs, data_dict['b_grads'], label='b grad norm', linewidth=2)\n",
    "    axes[1].plot(epochs, data_dict['eta_grads'], label='eta grad norm', linewidth=2)\n",
    "    axes[1].set_xlabel('epoch')\n",
    "    axes[1].set_ylabel('gradient norm')\n",
    "    axes[1].set_title('gradient norms')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # we plot learning rates\n",
    "    axes[2].plot(epochs, data_dict['lrs'], label='learning rate', linewidth=2)\n",
    "    axes[2].set_xlabel('epoch')\n",
    "    axes[2].set_ylabel('learning rate')\n",
    "    axes[2].set_title('learning rate schedule')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'dog_training_curves_epoch_{counter}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define main training setup\n",
    "if __name__ == \"__main__\":\n",
    "    # we set hyperparameters\n",
    "    base_lr = 1e-4\n",
    "    batch_size = 32\n",
    "    n_epochs = 5000\n",
    "    patch_size = 8\n",
    "    num_patches = 4\n",
    "    metrics_freq = 100\n",
    "    plot_freq = 500\n",
    "    \n",
    "    print(f\"\\nhyperparameters:\")\n",
    "    print(f\"  class: dog (cifar10 class 5)\")\n",
    "    print(f\"  batch_size: {batch_size}\")\n",
    "    print(f\"  learning_rate: {base_lr}\")\n",
    "    print(f\"  n_epochs: {n_epochs}\")\n",
    "    print(f\"  patch_size: {patch_size}\")\n",
    "    print(f\"  num_patches: {num_patches}\")\n",
    "    \n",
    "    # we define interpolant (one-sided linear interpolation)\n",
    "    path = 'one-sided-linear'\n",
    "    interpolant = stochastic_interpolant.Interpolant(path=path, gamma_type=None)\n",
    "    print(f\"\\nusing interpolant: {path}\")\n",
    "    \n",
    "    # we define loss functions\n",
    "    loss_fn_b = stochastic_interpolant.make_loss(\n",
    "        method='shared', interpolant=interpolant, loss_type='one-sided-b'\n",
    "    )\n",
    "    loss_fn_eta = stochastic_interpolant.make_loss(\n",
    "        method='shared', interpolant=interpolant, loss_type='one-sided-eta'\n",
    "    )\n",
    "    \n",
    "    # we create networks\n",
    "    print(\"\\ncreating u-net architectures...\")\n",
    "    unet_b = UNetDenoiser(in_channels=4, out_channels=3, base_channels=64)\n",
    "    unet_eta = UNetDenoiser(in_channels=4, out_channels=3, base_channels=64)\n",
    "    \n",
    "    b = VelocityNetwork(unet_b).to(itf.util.get_torch_device())\n",
    "    eta = EtaNetwork(unet_eta).to(itf.util.get_torch_device())\n",
    "    \n",
    "    # we count parameters\n",
    "    n_params_b = sum(p.numel() for p in b.parameters() if p.requires_grad)\n",
    "    n_params_eta = sum(p.numel() for p in eta.parameters() if p.requires_grad)\n",
    "    print(f\"b network parameters: {n_params_b:,}\")\n",
    "    print(f\"eta network parameters: {n_params_eta:,}\")\n",
    "    \n",
    "    # we create optimizers and schedulers\n",
    "    opt_b = torch.optim.Adam(b.parameters(), lr=base_lr)\n",
    "    opt_eta = torch.optim.Adam(eta.parameters(), lr=base_lr)\n",
    "    sched_b = torch.optim.lr_scheduler.CosineAnnealingLR(opt_b, T_max=n_epochs, eta_min=base_lr*0.01)\n",
    "    sched_eta = torch.optim.lr_scheduler.CosineAnnealingLR(opt_eta, T_max=n_epochs, eta_min=base_lr*0.01)\n",
    "    \n",
    "    # we initialize data dictionary\n",
    "    data_dict = {\n",
    "        'losses': [],\n",
    "        'b_losses': [],\n",
    "        'eta_losses': [],\n",
    "        'b_grads': [],\n",
    "        'eta_grads': [],\n",
    "        'lrs': []\n",
    "    }\n",
    "    \n",
    "    # we train the model\n",
    "    print(\"\\nstarting training...\\n\")\n",
    "    counter = 1\n",
    "    for epoch in range(n_epochs):\n",
    "        loss, b_loss, eta_loss, b_grad, eta_grad = train_step(\n",
    "            batch_size, interpolant, opt_b, opt_eta, sched_b, sched_eta,\n",
    "            patch_size, num_patches\n",
    "        )\n",
    "        \n",
    "        # we log metrics\n",
    "        if (counter - 1) % metrics_freq == 0:\n",
    "            data_dict['losses'].append(grab(loss).item())\n",
    "            data_dict['b_losses'].append(grab(b_loss).item())\n",
    "            data_dict['eta_losses'].append(grab(eta_loss).item())\n",
    "            data_dict['b_grads'].append(grab(b_grad).item())\n",
    "            data_dict['eta_grads'].append(grab(eta_grad).item())\n",
    "            data_dict['lrs'].append(opt_b.param_groups[0]['lr'])\n",
    "            \n",
    "            print(f\"epoch {counter}: loss={grab(loss).item():.4f}, b_loss={grab(b_loss).item():.4f}, eta_loss={grab(eta_loss).item():.4f}\")\n",
    "        \n",
    "        # we make plots\n",
    "        if (counter - 1) % plot_freq == 0:\n",
    "            make_plots(b, eta, interpolant, counter, data_dict, patch_size, num_patches)\n",
    "            \n",
    "            # we save checkpoints\n",
    "            torch.save({\n",
    "                'epoch': counter,\n",
    "                'b_state_dict': b.state_dict(),\n",
    "                'eta_state_dict': eta.state_dict(),\n",
    "                'opt_b_state_dict': opt_b.state_dict(),\n",
    "                'opt_eta_state_dict': opt_eta.state_dict(),\n",
    "                'data_dict': data_dict,\n",
    "                'class': 'dog',\n",
    "                'class_id': 5\n",
    "            }, f'dog_checkpoint_epoch_{counter}.pt')\n",
    "            print(f\"saved checkpoint at epoch {counter}\")\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    print(\"\\ntraining complete!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
