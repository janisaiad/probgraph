{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300165e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # we import os for filesystem operations\n",
    "import sys  # we import sys to modify path\n",
    "import time  # we import time for timing\n",
    "from typing import Any  # we import Any for type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ad0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # we import matplotlib for plotting\n",
    "import numpy as np  # we import numpy for array operations\n",
    "import torch  # we import torch for tensors\n",
    "import torch.nn as nn  # we import torch.nn for neural networks\n",
    "import torchvision  # we import torchvision for datasets\n",
    "import torchvision.transforms as transforms  # we import transforms for data preprocessing\n",
    "import urllib.request  # we import urllib to download files\n",
    "import zipfile  # we import zipfile to extract archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51977ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")  # we add project root to python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8989f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import interflow as itf  # we import interflow utilities\n",
    "import interflow.stochastic_interpolant as stochastic_interpolant  # we import stochastic interpolant tools\n",
    "from interflow import fabrics  # we import fabrics to build gamma schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d88914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available, setting default tensor residence to gpu\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janis/4A/probgraph/probgraph/.venv/lib/python3.12/site-packages/torch/__init__.py:1275: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  # we select cuda if available\n",
    "    print(\"cuda available, setting default tensor residence to gpu\")  # we log cuda availability\n",
    "    itf.util.set_torch_device(\"cuda\")  # we set torch device to cuda\n",
    "else:\n",
    "    print(\"no cuda device found\")  # we log absence of cuda\n",
    "print(itf.util.get_torch_device())  # we print currently selected device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba3f47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.9.0+cu128\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")  # we print torch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a0598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define utility functions\n",
    "def grab(var: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"we take a tensor off the gpu and convert it to a numpy array on the cpu\"\"\"  # we document grab\n",
    "    return var.detach().cpu().numpy()  # we convert tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faff8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load lsun dataset (bedroom class)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),  # we resize lsun images to 32x32\n",
    "        transforms.ToTensor(),  # we convert pil image to tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # we normalize channels\n",
    "    ]\n",
    ")  # we compose transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0d5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_lsun_bedroom(lsun_root: str) -> None:\n",
    "    \"\"\"we download and extract lsun bedroom_train_lmdb if missing\"\"\"  # we document lsun helper\n",
    "    bedroom_lmdb_dir = os.path.join(lsun_root, \"bedroom_train_lmdb\")  # we build expected lmdb directory\n",
    "    if os.path.isdir(bedroom_lmdb_dir):  # we check if directory already exists\n",
    "        print(f\"found existing lsun bedroom_train_lmdb at {bedroom_lmdb_dir}\")  # we log existing dataset\n",
    "        return  # we skip download when present\n",
    "    \n",
    "    os.makedirs(lsun_root, exist_ok=True)  # we ensure root directory exists\n",
    "    url = \"https://dl.yf.io/lsun/scenes/bedroom_train_lmdb.zip\"  # we set official lsun download url\n",
    "    zip_path = os.path.join(lsun_root, \"bedroom_train_lmdb.zip\")  # we choose local zip path\n",
    "    \n",
    "    print(f\"downloading lsun bedroom_train_lmdb from {url} to {zip_path} ...\")  # we log download start\n",
    "    urllib.request.urlretrieve(url, zip_path)  # we download zip archive\n",
    "    print(\"download complete, extracting archive...\")  # we log extraction start\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:  # we open zip file\n",
    "        zf.extractall(lsun_root)  # we extract all contents into root\n",
    "    \n",
    "    os.remove(zip_path)  # we remove zip file after extraction\n",
    "    print(f\"lsun bedroom_train_lmdb extracted to {bedroom_lmdb_dir}\")  # we log extraction location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365e7c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading lsun bedroom_train_lmdb from https://dl.yf.io/lsun/scenes/bedroom_train_lmdb.zip to ../../data/lsun/bedroom_train_lmdb.zip ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m lsun_root = \u001b[33m\"\u001b[39m\u001b[33m../../data/lsun\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# we set lsun root directory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mensure_lsun_bedroom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlsun_root\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# we ensure bedroom lmdb is available\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mensure_lsun_bedroom\u001b[39m\u001b[34m(lsun_root)\u001b[39m\n\u001b[32m     10\u001b[39m zip_path = os.path.join(lsun_root, \u001b[33m\"\u001b[39m\u001b[33mbedroom_train_lmdb.zip\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# we choose local zip path\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdownloading lsun bedroom_train_lmdb from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# we log download start\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# we download zip archive\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdownload complete, extracting archive...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# we log extraction start\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(zip_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zf:  \u001b[38;5;66;03m# we open zip file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:240\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    241\u001b[39m     headers = fp.info()\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/urllib/request.py:1344\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1342\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1343\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m         \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body=\u001b[38;5;28;01mNone\u001b[39;00m, headers={}, *,\n\u001b[32m   1336\u001b[39m             encode_chunked=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1091\u001b[39m msg = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._buffer)\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[32m   1098\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1099\u001b[39m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[32m   1100\u001b[39m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[32m   1101\u001b[39m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1039\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1472\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1470\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConnect to a host on a given (SSL) port.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1472\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m   1475\u001b[39m         server_hostname = \u001b[38;5;28mself\u001b[39m._tunnel_host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/http/client.py:1003\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1001\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[32m   1002\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/socket.py:850\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m    849\u001b[39m     sock.bind(source_address)\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m    852\u001b[39m exceptions.clear()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lsun_root = \"../../data/lsun\"  # we set lsun root directory\n",
    "ensure_lsun_bedroom(lsun_root)  # we ensure bedroom lmdb is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbfb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.LSUN(\n",
    "    root=lsun_root, classes=[\"bedroom_train\"], transform=transform\n",
    ")  # we load lsun bedroom training set\n",
    "print(f\"\\nloaded lsun bedroom_train: {len(trainset)} images\")  # we log lsun subset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89417f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create data iterator that only samples from lsun bedroom images\n",
    "def get_cifar_batch(bs: int) -> torch.Tensor:\n",
    "    \"\"\"we get a batch of lsun bedroom images only\"\"\"  # we document get_cifar_batch\n",
    "    indices = torch.randint(0, len(trainset), (bs,))  # we sample random indices\n",
    "    imgs = torch.stack([trainset[i][0] for i in indices])  # we stack selected images\n",
    "    return imgs.to(itf.util.get_torch_device())  # we move batch to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4158af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create masking function for patches\n",
    "def create_patch_mask(bs: int, patch_size: int = 8, num_patches: int = 4) -> torch.Tensor:\n",
    "    \"\"\"we create random patch masks, 1 for visible pixels, 0 for masked patches\"\"\"  # we document create_patch_mask\n",
    "    mask = torch.ones(bs, 3, 32, 32)  # we start with all ones\n",
    "    for i in range(bs):  # we iterate over batch\n",
    "        for _ in range(num_patches):  # we add a number of patches\n",
    "            x = torch.randint(0, 32 - patch_size, (1,)).item()  # we choose x coordinate\n",
    "            y = torch.randint(0, 32 - patch_size, (1,)).item()  # we choose y coordinate\n",
    "            mask[i, :, x : x + patch_size, y : y + patch_size] = 0  # we mask the patch\n",
    "    return mask.to(itf.util.get_torch_device())  # we move mask to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define u-net style convolutional denoiser for image reconstruction\n",
    "class UNetDenoiser(nn.Module):\n",
    "    \"\"\"we use u-net architecture with skip connections for image reconstruction\"\"\"  # we describe unet\n",
    "\n",
    "    def __init__(self, in_channels: int = 4, out_channels: int = 3, base_channels: int = 64) -> None:\n",
    "        super().__init__()  # we call parent constructor\n",
    "\n",
    "        # we define encoder (downsampling path)\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, 3, padding=1),  # we define first conv layer\n",
    "            nn.GroupNorm(8, base_channels),  # we normalize features\n",
    "            nn.ReLU(),  # we apply nonlinearity\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),  # we define second conv\n",
    "            nn.GroupNorm(8, base_channels),  # we normalize again\n",
    "            nn.ReLU(),  # we add nonlinearity\n",
    "        )  # we build first encoder block\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels * 2, 3, stride=2, padding=1),  # we downsample\n",
    "            nn.GroupNorm(8, base_channels * 2),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 3, padding=1),  # we refine features\n",
    "            nn.GroupNorm(8, base_channels * 2),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build second encoder block\n",
    "\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 4, 3, stride=2, padding=1),  # we downsample deeper\n",
    "            nn.GroupNorm(8, base_channels * 4),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 4, 3, padding=1),  # we refine\n",
    "            nn.GroupNorm(8, base_channels * 4),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build third encoder block\n",
    "\n",
    "        # we define bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 8, 3, stride=2, padding=1),  # we downsample to bottleneck\n",
    "            nn.GroupNorm(8, base_channels * 8),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "            nn.Conv2d(base_channels * 8, base_channels * 8, 3, padding=1),  # we refine\n",
    "            nn.GroupNorm(8, base_channels * 8),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build bottleneck block\n",
    "\n",
    "        # we define decoder (upsampling path) with skip connections\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                base_channels * 8, base_channels * 4, 3, stride=2, padding=1, output_padding=1\n",
    "            ),  # we upsample\n",
    "            nn.GroupNorm(8, base_channels * 4),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build first decoder upsample block\n",
    "        self.dec3_conv = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 8, base_channels * 4, 3, padding=1),  # we fuse skip connection\n",
    "            nn.GroupNorm(8, base_channels * 4),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 4, 3, padding=1),  # we refine\n",
    "            nn.GroupNorm(8, base_channels * 4),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build first decoder conv block\n",
    "\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                base_channels * 4, base_channels * 2, 3, stride=2, padding=1, output_padding=1\n",
    "            ),  # we upsample\n",
    "            nn.GroupNorm(8, base_channels * 2),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build second decoder upsample block\n",
    "        self.dec2_conv = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 2, 3, padding=1),  # we fuse skip connection\n",
    "            nn.GroupNorm(8, base_channels * 2),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 3, padding=1),  # we refine\n",
    "            nn.GroupNorm(8, base_channels * 2),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build second decoder conv block\n",
    "\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_channels * 2, base_channels, 3, stride=2, padding=1, output_padding=1),  # we upsample\n",
    "            nn.GroupNorm(8, base_channels),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build third decoder upsample block\n",
    "        self.dec1_conv = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels, 3, padding=1),  # we fuse skip connection\n",
    "            nn.GroupNorm(8, base_channels),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),  # we refine\n",
    "            nn.GroupNorm(8, base_channels),  # we normalize\n",
    "            nn.ReLU(),  # we activate\n",
    "        )  # we build third decoder conv block\n",
    "\n",
    "        # we define final output layer\n",
    "        self.final = nn.Conv2d(base_channels, out_channels, 1)  # we map features to rgb channels\n",
    "\n",
    "    def forward(self, x_with_t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"we forward pass with skip connections\"\"\"  # we describe forward\n",
    "        # we encode\n",
    "        e1 = self.enc1(x_with_t)  # we apply first encoder block\n",
    "        e2 = self.enc2(e1)  # we apply second encoder block\n",
    "        e3 = self.enc3(e2)  # we apply third encoder block\n",
    "\n",
    "        # we process bottleneck\n",
    "        b = self.bottleneck(e3)  # we compute bottleneck features\n",
    "\n",
    "        # we decode with skip connections\n",
    "        d3 = self.dec3(b)  # we upsample from bottleneck\n",
    "        d3 = torch.cat([d3, e3], dim=1)  # we concatenate skip from encoder level 3\n",
    "        d3 = self.dec3_conv(d3)  # we refine fused features\n",
    "\n",
    "        d2 = self.dec2(d3)  # we upsample\n",
    "        d2 = torch.cat([d2, e2], dim=1)  # we concatenate skip from encoder level 2\n",
    "        d2 = self.dec2_conv(d2)  # we refine\n",
    "\n",
    "        d1 = self.dec1(d2)  # we upsample\n",
    "        d1 = torch.cat([d1, e1], dim=1)  # we concatenate skip from encoder level 1\n",
    "        d1 = self.dec1_conv(d1)  # we refine\n",
    "\n",
    "        # we output final reconstruction\n",
    "        out = self.final(d1)  # we map to rgb\n",
    "        return out  # we return reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66811c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define wrapper for eta network to match expected interface\n",
    "class EtaNetwork(nn.Module):\n",
    "    \"\"\"we wrap unet to accept separate (x, t) inputs\"\"\"  # we describe eta wrapper\n",
    "\n",
    "    def __init__(self, unet: nn.Module) -> None:\n",
    "        super().__init__()  # we call parent constructor\n",
    "        self.unet = unet  # we store underlying unet\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: Any) -> torch.Tensor:\n",
    "        \"\"\"we expect x of shape [bs, 3*32*32] and scalar or batched t\"\"\"  # we describe eta forward\n",
    "        bs = x.shape[0]  # we get batch size\n",
    "        x_img = x.reshape(bs, 3, 32, 32)  # we reshape flat image to 4d tensor\n",
    "\n",
    "        if not isinstance(t, torch.Tensor):  # we convert non-tensor time to tensor\n",
    "            t_tensor = torch.tensor(t, device=x.device, dtype=x.dtype)  # we build tensor from scalar or array\n",
    "        else:\n",
    "            t_tensor = t.to(x.device)  # we move time tensor to same device as x\n",
    "\n",
    "        if t_tensor.dim() == 0:  # we handle scalar time\n",
    "            t_batch = t_tensor.repeat(bs).unsqueeze(1)  # we repeat scalar t over batch\n",
    "        elif t_tensor.dim() == 1:  # we handle vector time\n",
    "            if t_tensor.shape[0] == 1 and bs > 1:  # we broadcast single time value to batch\n",
    "                t_batch = t_tensor.repeat(bs).unsqueeze(1)  # we repeat along batch dimension\n",
    "            else:\n",
    "                t_batch = t_tensor.unsqueeze(1)  # we add feature dimension\n",
    "        elif t_tensor.dim() == 2:  # we handle matrix-shaped time\n",
    "            if t_tensor.shape[0] == 1 and bs > 1:  # we broadcast row to batch\n",
    "                t_batch = t_tensor.repeat(bs, 1)  # we repeat row across batch\n",
    "            else:\n",
    "                t_batch = t_tensor  # we assume proper shape [bs, 1]\n",
    "        else:\n",
    "            raise ValueError(\"we expect time tensor of dimension at most 2\")  # we guard against unsupported shapes\n",
    "\n",
    "        t_channel = t_batch.view(bs, 1, 1, 1).expand(bs, 1, 32, 32)  # we broadcast time as extra channel\n",
    "        x_with_t = torch.cat([x_img, t_channel], dim=1)  # we concatenate time as 4th channel\n",
    "\n",
    "        out = self.unet(x_with_t)  # we run unet\n",
    "        return out.reshape(bs, -1)  # we flatten output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5391ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define velocity field wrapper\n",
    "class VelocityNetwork(nn.Module):\n",
    "    \"\"\"we wrap unet for velocity field b with separate (x, t) inputs\"\"\"  # we describe velocity wrapper\n",
    "\n",
    "    def __init__(self, unet: nn.Module) -> None:\n",
    "        super().__init__()  # we call parent constructor\n",
    "        self.unet = unet  # we store underlying unet\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: Any) -> torch.Tensor:\n",
    "        \"\"\"we expect x of shape [bs, 3*32*32] and scalar or batched t\"\"\"  # we describe velocity forward\n",
    "        bs = x.shape[0]  # we get batch size\n",
    "        x_img = x.reshape(bs, 3, 32, 32)  # we reshape flat image to 4d tensor\n",
    "\n",
    "        if not isinstance(t, torch.Tensor):  # we convert non-tensor time to tensor\n",
    "            t_tensor = torch.tensor(t, device=x.device, dtype=x.dtype)  # we build tensor from scalar or array\n",
    "        else:\n",
    "            t_tensor = t.to(x.device)  # we move time tensor to same device as x\n",
    "\n",
    "        if t_tensor.dim() == 0:  # we handle scalar time\n",
    "            t_batch = t_tensor.repeat(bs).unsqueeze(1)  # we repeat scalar t over batch\n",
    "        elif t_tensor.dim() == 1:  # we handle vector time\n",
    "            if t_tensor.shape[0] == 1 and bs > 1:  # we broadcast single time value to batch\n",
    "                t_batch = t_tensor.repeat(bs).unsqueeze(1)  # we repeat along batch dimension\n",
    "            else:\n",
    "                t_batch = t_tensor.unsqueeze(1)  # we add feature dimension\n",
    "        elif t_tensor.dim() == 2:  # we handle matrix-shaped time\n",
    "            if t_tensor.shape[0] == 1 and bs > 1:  # we broadcast row to batch\n",
    "                t_batch = t_tensor.repeat(bs, 1)  # we repeat row across batch\n",
    "            else:\n",
    "                t_batch = t_tensor  # we assume proper shape [bs, 1]\n",
    "        else:\n",
    "            raise ValueError(\"we expect time tensor of dimension at most 2\")  # we guard against unsupported shapes\n",
    "\n",
    "        t_channel = t_batch.view(bs, 1, 1, 1).expand(bs, 1, 32, 32)  # we broadcast time as extra channel\n",
    "        x_with_t = torch.cat([x_img, t_channel], dim=1)  # we concatenate time as 4th channel\n",
    "\n",
    "        out = self.unet(x_with_t)  # we run unet\n",
    "        return out.reshape(bs, -1)  # we flatten output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define training step function\n",
    "def train_step(\n",
    "    bs: int,\n",
    "    interpolant: stochastic_interpolant.Interpolant,\n",
    "    opt_b: Any,\n",
    "    opt_eta: Any,\n",
    "    sched_b: Any,\n",
    "    sched_eta: Any,\n",
    "    patch_size: int,\n",
    "    num_patches: int,\n",
    "    mask_loss_weight: float = 10.0,\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"we take a single step of optimization on the training set\"\"\"  # we document train_step\n",
    "    opt_b.zero_grad()  # we reset gradients for b\n",
    "    opt_eta.zero_grad()  # we reset gradients for eta\n",
    "\n",
    "    # we construct batch of real images\n",
    "    x1s_img = get_cifar_batch(bs)  # we get [bs, 3, 32, 32]\n",
    "\n",
    "    # we create masks\n",
    "    masks = create_patch_mask(bs, patch_size=patch_size, num_patches=num_patches)  # we get [bs, 3, 32, 32]\n",
    "\n",
    "    # we create masked images + noise in masked regions as starting point\n",
    "    noise = torch.randn_like(x1s_img) * (1 - masks)  # we add noise only in masked regions\n",
    "    x0s_img = x1s_img * masks + noise  # we combine masked image and noise\n",
    "\n",
    "    # we flatten for interpolant\n",
    "    x0s = x0s_img.reshape(bs, -1)  # we flatten to [bs, 3072]\n",
    "    x1s = x1s_img.reshape(bs, -1)  # we flatten to [bs, 3072]\n",
    "    _ = masks.reshape(bs, -1)  # we flatten mask too (unused but kept for clarity)\n",
    "\n",
    "    # we sample random times\n",
    "    ts = torch.rand(size=(bs,)).to(itf.util.get_torch_device())  # we sample times in [0,1]\n",
    "\n",
    "    # we compute the losses\n",
    "    loss_start = time.perf_counter()  # we record loss computation start\n",
    "    loss_b = loss_fn_b(b, x0s, x1s, ts, interpolant)  # we compute b loss\n",
    "    loss_eta = loss_fn_eta(eta, x0s, x1s, ts, interpolant)  # we compute eta loss\n",
    "\n",
    "    # we add extra weight to loss on masked regions (currently unused, kept for compatibility)\n",
    "    loss_val = loss_b + loss_eta  # we combine losses\n",
    "    loss_end = time.perf_counter()  # we record loss computation end\n",
    "\n",
    "    # we compute the gradient\n",
    "    backprop_start = time.perf_counter()  # we record backprop start\n",
    "    loss_b.backward()  # we backpropagate through b\n",
    "    loss_eta.backward()  # we backpropagate through eta\n",
    "    b_grad = torch.tensor(\n",
    "        [torch.nn.utils.clip_grad_norm_(b.parameters(), float(\"inf\"))]\n",
    "    )  # we clip and record b gradient norm\n",
    "    eta_grad = torch.tensor(\n",
    "        [torch.nn.utils.clip_grad_norm_(eta.parameters(), float(\"inf\"))]\n",
    "    )  # we clip and record eta gradient norm\n",
    "    backprop_end = time.perf_counter()  # we record backprop end\n",
    "\n",
    "    # we perform the update\n",
    "    update_start = time.perf_counter()  # we record update start\n",
    "    opt_b.step()  # we update b\n",
    "    opt_eta.step()  # we update eta\n",
    "    sched_b.step()  # we step scheduler for b\n",
    "    sched_eta.step()  # we step scheduler for eta\n",
    "    update_end = time.perf_counter()  # we record update end\n",
    "\n",
    "    if counter < 5:  # we print timings for first few steps\n",
    "        print(\n",
    "            f\"[loss: {loss_end - loss_start:.4f}s], \"\n",
    "            f\"[backprop: {backprop_end - backprop_start:.4f}s], \"\n",
    "            f\"[update: {update_end - update_start:.4f}s]\"\n",
    "        )  # we log timing information\n",
    "\n",
    "    return loss_val.detach(), loss_b.detach(), loss_eta.detach(), b_grad.detach(), eta_grad.detach()  # we return detached values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define visualization function\n",
    "def make_plots(\n",
    "    b: torch.nn.Module,\n",
    "    eta: torch.nn.Module,\n",
    "    interpolant: stochastic_interpolant.Interpolant,\n",
    "    counter: int,\n",
    "    data_dict: dict,\n",
    "    patch_size: int,\n",
    "    num_patches: int,\n",
    ") -> None:\n",
    "    \"\"\"we make plots to visualize reconstruction results\"\"\"  # we document make_plots\n",
    "    print(f\"\\nepoch: {counter}\")  # we log epoch\n",
    "\n",
    "    # we get a batch for visualization\n",
    "    vis_bs = 8  # we set visualization batch size\n",
    "    x1s_img = get_cifar_batch(vis_bs)  # we sample images\n",
    "    masks = create_patch_mask(vis_bs, patch_size=patch_size, num_patches=num_patches)  # we create masks\n",
    "\n",
    "    # we create masked images\n",
    "    noise = torch.randn_like(x1s_img) * (1 - masks)  # we add noise only in masked regions\n",
    "    x0s_img = x1s_img * masks + noise  # we create corrupted images\n",
    "\n",
    "    # we reconstruct using probability flow\n",
    "    x0s = x0s_img.reshape(vis_bs, -1)  # we flatten starting points\n",
    "    _ = x1s_img.reshape(vis_bs, -1)  # we flatten targets (unused here)\n",
    "\n",
    "    # we use simple forward integration\n",
    "    with torch.no_grad():  # we disable gradients for sampling\n",
    "        _ = stochastic_interpolant.SFromEta(eta, interpolant.a)  # we build score from eta (unused here but kept)\n",
    "        pflow = stochastic_interpolant.PFlowIntegrator(\n",
    "            b=b, method=\"dopri5\", interpolant=interpolant, n_step=10\n",
    "        )  # we build probability flow integrator\n",
    "        xfs_pflow, _ = pflow.rollout(x0s)  # we rollout from x0s\n",
    "        xf_pflow = xfs_pflow[-1].reshape(vis_bs, 3, 32, 32)  # we take final states and reshape\n",
    "\n",
    "    # we plot results\n",
    "    fig, axes = plt.subplots(3, vis_bs, figsize=(vis_bs * 2, 6))  # we create figure\n",
    "\n",
    "    for i in range(vis_bs):  # we iterate over visualization batch\n",
    "        # we denormalize images for visualization\n",
    "        def denorm(img: torch.Tensor) -> torch.Tensor:\n",
    "            return img * 0.5 + 0.5  # we revert normalization\n",
    "\n",
    "        # we show original image\n",
    "        axes[0, i].imshow(np.transpose(grab(denorm(x1s_img[i])), (1, 2, 0)))  # we plot original\n",
    "        axes[0, i].axis(\"off\")  # we hide axes\n",
    "        if i == 0:  # we add title to first column\n",
    "            axes[0, i].set_title(\"original\", fontsize=10)  # we set title\n",
    "\n",
    "        # we show masked image\n",
    "        axes[1, i].imshow(np.transpose(grab(denorm(x0s_img[i])), (1, 2, 0)))  # we plot corrupted\n",
    "        axes[1, i].axis(\"off\")  # we hide axes\n",
    "        if i == 0:  # we add title to first column\n",
    "            axes[1, i].set_title(\"masked\", fontsize=10)  # we set title\n",
    "\n",
    "        # we show reconstructed image\n",
    "        axes[2, i].imshow(np.transpose(grab(denorm(xf_pflow[i])), (1, 2, 0)))  # we plot reconstructions\n",
    "        axes[2, i].axis(\"off\")  # we hide axes\n",
    "        if i == 0:  # we add title to first column\n",
    "            axes[2, i].set_title(\"reconstructed\", fontsize=10)  # we set title\n",
    "\n",
    "    plt.suptitle(f\"dog patch reconstruction - epoch {counter}\", fontsize=14, y=1.02)  # we add global title\n",
    "    plt.tight_layout()  # we adjust layout\n",
    "    results_dir = os.path.join(\"vresults\", \"cifarpatchedinterpolants\")  # we define directory for saving figures\n",
    "    os.makedirs(results_dir, exist_ok=True)  # we ensure results directory exists\n",
    "    recon_path = os.path.join(\n",
    "        results_dir,\n",
    "        f\"dog_reconstruction_epoch_{counter}.png\",\n",
    "    )  # we build reconstruction path\n",
    "    plt.savefig(recon_path, dpi=150, bbox_inches=\"tight\")  # we save reconstruction figure\n",
    "    plt.show()  # we display figure\n",
    "\n",
    "    # we plot training curves\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))  # we create figure for curves\n",
    "\n",
    "    epochs = np.arange(len(data_dict[\"losses\"])) * metrics_freq  # we build epoch axis\n",
    "\n",
    "    # we plot losses\n",
    "    axes[0].plot(epochs, data_dict[\"losses\"], label=\"total loss\", linewidth=2)  # we plot total loss\n",
    "    axes[0].plot(epochs, data_dict[\"b_losses\"], label=\"b loss\", alpha=0.7)  # we plot b loss\n",
    "    axes[0].plot(epochs, data_dict[\"eta_losses\"], label=\"eta loss\", alpha=0.7)  # we plot eta loss\n",
    "    axes[0].set_xlabel(\"epoch\")  # we label x axis\n",
    "    axes[0].set_ylabel(\"loss\")  # we label y axis\n",
    "    axes[0].set_title(\"training loss (dog class)\")  # we set title\n",
    "    axes[0].legend()  # we add legend\n",
    "    axes[0].grid(True, alpha=0.3)  # we add grid\n",
    "\n",
    "    # we plot gradients\n",
    "    axes[1].plot(epochs, data_dict[\"b_grads\"], label=\"b grad norm\", linewidth=2)  # we plot b gradient norm\n",
    "    axes[1].plot(epochs, data_dict[\"eta_grads\"], label=\"eta grad norm\", linewidth=2)  # we plot eta gradient norm\n",
    "    axes[1].set_xlabel(\"epoch\")  # we label x axis\n",
    "    axes[1].set_ylabel(\"gradient norm\")  # we label y axis\n",
    "    axes[1].set_title(\"gradient norms\")  # we set title\n",
    "    axes[1].legend()  # we add legend\n",
    "    axes[1].grid(True, alpha=0.3)  # we add grid\n",
    "\n",
    "    # we plot learning rates\n",
    "    axes[2].plot(epochs, data_dict[\"lrs\"], label=\"learning rate\", linewidth=2)  # we plot learning rate\n",
    "    axes[2].set_xlabel(\"epoch\")  # we label x axis\n",
    "    axes[2].set_ylabel(\"learning rate\")  # we label y axis\n",
    "    axes[2].set_title(\"learning rate schedule\")  # we set title\n",
    "    axes[2].legend()  # we add legend\n",
    "    axes[2].grid(True, alpha=0.3)  # we add grid\n",
    "\n",
    "    path_name = interpolant.path  # we get interpolant path name\n",
    "    gamma_name = getattr(interpolant, \"gamma_type\", \"none\")  # we get gamma schedule name\n",
    "    epsilon_name = getattr(interpolant, \"epsilon\", 1.0)  # we get epsilon value\n",
    "\n",
    "    plt.tight_layout()  # we adjust layout\n",
    "    os.makedirs(results_dir, exist_ok=True)  # we ensure results directory exists\n",
    "    curves_path = os.path.join(\n",
    "        results_dir,\n",
    "        f\"dog_training_curves_{path_name}_{gamma_name}_eps{epsilon_name}_epoch_{counter}.png\",\n",
    "    )  # we build curves path\n",
    "    plt.savefig(curves_path, dpi=150, bbox_inches=\"tight\")  # we save curves figure\n",
    "    plt.show()  # we display figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109600a4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# we define main training setup with epsilon sweep\n",
    "if __name__ == \"__main__\":  # we enter main script\n",
    "    # we set hyperparameters\n",
    "    base_lr = 1e-4  # we set base learning rate\n",
    "    batch_size = 32  # we set batch size\n",
    "    n_epochs = 5000  # we set number of epochs\n",
    "    patch_size = 8  # we set patch size\n",
    "    num_patches = 4  # we set number of patches\n",
    "    metrics_freq = 100  # we set metrics logging frequency\n",
    "    plot_freq = 500  # we set plotting frequency\n",
    "\n",
    "    print(\"\\nhyperparameters:\")  # we print header for hyperparameters\n",
    "    print(f\"  class: dog (cifar10 class 5)\")  # we print target class\n",
    "    print(f\"  batch_size: {batch_size}\")  # we print batch size\n",
    "    print(f\"  learning_rate: {base_lr}\")  # we print base learning rate\n",
    "    print(f\"  n_epochs: {n_epochs}\")  # we print number of epochs\n",
    "    print(f\"  patch_size: {patch_size}\")  # we print patch size\n",
    "    print(f\"  num_patches: {num_patches}\")  # we print number of patches\n",
    "\n",
    "    paths = [\"linear\", \"trig\", \"encoding-decoding\"]  # we define two-sided interpolant paths\n",
    "    gamma_types = [\"bsquared\", \"sinesquared\", \"sigmoid\"]  # we define non-gaussian gamma schedules\n",
    "    epsilons = [0.1, 0.2, 0.5, 1.0]  # we define epsilon sweep values\n",
    "\n",
    "    for epsilon in epsilons:  # we loop over epsilon values\n",
    "        for path in paths:  # we loop over interpolant paths\n",
    "            for gamma_type in gamma_types:  # we loop over gamma schedules\n",
    "                print(\n",
    "                    f\"\\nusing interpolant: path={path}, gamma_type={gamma_type}, epsilon={epsilon}\"\n",
    "                )  # we log current interpolant config\n",
    "\n",
    "                base_gamma, base_gamma_dot, base_gg_dot = fabrics.make_gamma(\n",
    "                    gamma_type=gamma_type\n",
    "                )  # we get base gamma functions\n",
    "\n",
    "                def scaled_gamma(t: torch.Tensor, g=base_gamma, eps: float = epsilon) -> torch.Tensor:\n",
    "                    return eps * g(t)  # we scale gamma amplitude\n",
    "\n",
    "                def scaled_gamma_dot(t: torch.Tensor, gd=base_gamma_dot, eps: float = epsilon) -> torch.Tensor:\n",
    "                    return eps * gd(t)  # we scale gamma derivative amplitude\n",
    "\n",
    "                def scaled_gg_dot(t: torch.Tensor, ggd=base_gg_dot, eps: float = epsilon) -> torch.Tensor:\n",
    "                    return (eps**2) * ggd(t)  # we scale gamma*gamma_dot amplitude\n",
    "\n",
    "                interpolant = stochastic_interpolant.Interpolant(\n",
    "                    path=path,\n",
    "                    gamma_type=None,\n",
    "                    gamma=scaled_gamma,\n",
    "                    gamma_dot=scaled_gamma_dot,\n",
    "                    gg_dot=scaled_gg_dot,\n",
    "                )  # we create interpolant with scaled non-gaussian gamma\n",
    "                interpolant.gamma_type = gamma_type  # we store gamma type on interpolant for logging\n",
    "                interpolant.epsilon = float(epsilon)  # we store epsilon on interpolant for logging\n",
    "\n",
    "                # we define loss functions for two-sided stochastic interpolant\n",
    "                loss_fn_b = stochastic_interpolant.make_loss(\n",
    "                    method=\"shared\", interpolant=interpolant, loss_type=\"b\"\n",
    "                )  # we build b loss\n",
    "                loss_fn_eta = stochastic_interpolant.make_loss(\n",
    "                    method=\"shared\", interpolant=interpolant, loss_type=\"eta\"\n",
    "                )  # we build eta loss\n",
    "\n",
    "                # we create networks\n",
    "                print(\"\\ncreating u-net architectures...\")  # we notify network instantiation\n",
    "                unet_b = UNetDenoiser(\n",
    "                    in_channels=4, out_channels=3, base_channels=64\n",
    "                )  # we create u-net for b\n",
    "                unet_eta = UNetDenoiser(\n",
    "                    in_channels=4, out_channels=3, base_channels=64\n",
    "                )  # we create u-net for eta\n",
    "\n",
    "                b = VelocityNetwork(unet_b).to(itf.util.get_torch_device())  # we move b network to device\n",
    "                eta = EtaNetwork(unet_eta).to(itf.util.get_torch_device())  # we move eta network to device\n",
    "\n",
    "                # we count parameters\n",
    "                n_params_b = sum(p.numel() for p in b.parameters() if p.requires_grad)  # we count params of b\n",
    "                n_params_eta = sum(\n",
    "                    p.numel() for p in eta.parameters() if p.requires_grad\n",
    "                )  # we count params of eta\n",
    "                print(f\"b network parameters: {n_params_b:,}\")  # we print number of parameters of b\n",
    "                print(f\"eta network parameters: {n_params_eta:,}\")  # we print number of parameters of eta\n",
    "\n",
    "                # we create optimizers and schedulers\n",
    "                opt_b = torch.optim.Adam(b.parameters(), lr=base_lr)  # we create optimizer for b\n",
    "                opt_eta = torch.optim.Adam(eta.parameters(), lr=base_lr)  # we create optimizer for eta\n",
    "                sched_b = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    opt_b, T_max=n_epochs, eta_min=base_lr * 0.01\n",
    "                )  # we create lr scheduler for b\n",
    "                sched_eta = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    opt_eta, T_max=n_epochs, eta_min=base_lr * 0.01\n",
    "                )  # we create lr scheduler for eta\n",
    "\n",
    "                # we initialize data dictionary\n",
    "                data_dict: dict[str, list[float]] = {\n",
    "                    \"losses\": [],\n",
    "                    \"b_losses\": [],\n",
    "                    \"eta_losses\": [],\n",
    "                    \"b_grads\": [],\n",
    "                    \"eta_grads\": [],\n",
    "                    \"lrs\": [],\n",
    "                }  # we store training metrics\n",
    "\n",
    "                # we train the model for this configuration\n",
    "                print(\"\\nstarting training...\\n\")  # we announce training start\n",
    "                counter = 1  # we initialize iteration counter\n",
    "                for epoch in range(n_epochs):  # we iterate over epochs\n",
    "                    (\n",
    "                        loss,\n",
    "                        b_loss,\n",
    "                        eta_loss,\n",
    "                        b_grad,\n",
    "                        eta_grad,\n",
    "                    ) = train_step(\n",
    "                        batch_size,\n",
    "                        interpolant,\n",
    "                        opt_b,\n",
    "                        opt_eta,\n",
    "                        sched_b,\n",
    "                        sched_eta,\n",
    "                        patch_size,\n",
    "                        num_patches,\n",
    "                    )  # we perform one training step\n",
    "\n",
    "                    # we log metrics\n",
    "                    if (counter - 1) % metrics_freq == 0:  # we log at chosen frequency\n",
    "                        data_dict[\"losses\"].append(grab(loss).item())  # we log total loss\n",
    "                        data_dict[\"b_losses\"].append(grab(b_loss).item())  # we log b loss\n",
    "                        data_dict[\"eta_losses\"].append(grab(eta_loss).item())  # we log eta loss\n",
    "                        data_dict[\"b_grads\"].append(grab(b_grad).item())  # we log gradient norm of b\n",
    "                        data_dict[\"eta_grads\"].append(grab(eta_grad).item())  # we log gradient norm of eta\n",
    "                        data_dict[\"lrs\"].append(opt_b.param_groups[0][\"lr\"])  # we log learning rate\n",
    "\n",
    "                        print(\n",
    "                            f\"[path={path} | gamma_type={gamma_type} | eps={epsilon}] \"\n",
    "                            f\"epoch {counter}: \"\n",
    "                            f\"loss={grab(loss).item():.4f}, \"\n",
    "                            f\"b_loss={grab(b_loss).item():.4f}, \"\n",
    "                            f\"eta_loss={grab(eta_loss).item():.4f}\"\n",
    "                        )  # we print training status\n",
    "\n",
    "                    # we make plots and save checkpoints\n",
    "                    if (counter - 1) % plot_freq == 0:  # we plot at chosen frequency\n",
    "                        make_plots(\n",
    "                            b, eta, interpolant, counter, data_dict, patch_size, num_patches\n",
    "                        )  # we visualize results\n",
    "\n",
    "                        results_dir = os.path.join(\n",
    "                            \"vresults\", \"cifarpatchedinterpolants\"\n",
    "                        )  # we define directory for checkpoints\n",
    "                        os.makedirs(results_dir, exist_ok=True)  # we ensure results directory exists\n",
    "                        ckpt_name = os.path.join(\n",
    "                            results_dir,\n",
    "                            f\"dog_checkpoint_{path}_{gamma_type}_eps{epsilon}_epoch_{counter}.pt\",\n",
    "                        )  # we build checkpoint filename\n",
    "                        torch.save(\n",
    "                            {\n",
    "                                \"epoch\": counter,\n",
    "                                \"b_state_dict\": b.state_dict(),\n",
    "                                \"eta_state_dict\": eta.state_dict(),\n",
    "                                \"opt_b_state_dict\": opt_b.state_dict(),\n",
    "                                \"opt_eta_state_dict\": opt_eta.state_dict(),\n",
    "                                \"data_dict\": data_dict,\n",
    "                                \"class\": \"dog\",\n",
    "                                \"class_id\": 5,\n",
    "                                \"path\": path,\n",
    "                                \"gamma_type\": gamma_type,\n",
    "                                \"epsilon\": float(epsilon),\n",
    "                            },\n",
    "                            ckpt_name,\n",
    "                        )  # we save checkpoint\n",
    "                        print(\n",
    "                            f\"saved checkpoint at epoch {counter} for path={path}, gamma_type={gamma_type}, eps={epsilon}\"\n",
    "                        )  # we log checkpoint saving\n",
    "\n",
    "                    counter += 1  # we increment iteration counter\n",
    "\n",
    "                print(\n",
    "                    f\"\\ntraining complete for path={path}, gamma_type={gamma_type}, eps={epsilon}\\n\"\n",
    "                )  # we mark configuration as finished"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
